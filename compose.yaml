# Define a reusable logging block for Loki
x-logging-loki: &loki-logging
  driver: loki
  options:
    loki-url: ${LOKI_URL:-http://localhost:3100/loki/api/v1/push}
    labels: "service={{.Name}}"

services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    volumes:
      - ollama:/root/.ollama
    ports:
      - "11434:11434"
    networks:
      - localai-hub
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/"]
      interval: 30s
      timeout: 5s
      retries: 3
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    logging: *loki-logging

  open-webui:
    image: ghcr.io/open-webui/open-webui
    container_name: open-webui
    ports:
      - "3000:8080"
    volumes:
      - ollama:/root/.ollama
      - open-webui:/app/backend/data
    env_file:
      - "./env/postgres.env"
      - "./env/openwebui.env"
    environment:
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://prometheus:9090
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      - ollama
      - redis
      - pipelines
      - qdrant
      - tika
      - searxng
      - loki
      - prometheus
      - grafana
      - caddy
      - playwright
      - cadvisor
      - postgres
      - redis-exporter
    restart: unless-stopped
    networks:
      - localai-hub
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 5s
      retries: 3
    logging: *loki-logging

  searxng:
    image: searxng/searxng:latest
    container_name: searxng
    ports:
      - "8080:8080"
    volumes:
      - ./searxng:/etc/searxng:rw
      - searxng-cache:/var/cache/searxng
    env_file:
      - "./env/searxng.env"
    depends_on:
      - redis
      - sysctl-setter
    restart: unless-stopped
    networks:
      - localai-hub
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETGID
      - SETUID
      - DAC_OVERRIDE
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/"]
      interval: 30s
      timeout: 5s
      retries: 3
    logging: *loki-logging

  caddy:
    image: docker.io/library/caddy:2-alpine
    container_name: caddy
    ports:
      - "80:80"
      - "443:443"
      - "2019:2019"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    env_file:
      - "./env/caddy.env"
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile:ro
      - caddy-data:/data
      - caddy-config:/config
    restart: unless-stopped
    networks:
      - localai-hub
    cap_drop:
      - ALL
    cap_add:
      - NET_BIND_SERVICE
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:2019/metrics"]
      interval: 30s
      timeout: 5s
      retries: 3
    logging: *loki-logging

  tika:
    image: apache/tika:latest-full
    container_name: tika
    ports:
      - "9998:9998"
    restart: unless-stopped
    networks:
      - localai-hub
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9998/tika || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging: *loki-logging

  pipelines:
    image: ghcr.io/open-webui/pipelines:main
    container_name: pipelines
    ports:
      - "9099:9099"
    volumes:
      - pipelines:/app/pipelines
    restart: unless-stopped
    networks:
      - localai-hub
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9099"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging: *loki-logging

  sysctl-setter:
    image: alpine:latest
    container_name: sysctl-setter
    privileged: true
    command: sh -c "sysctl -w vm.overcommit_memory=1"
    networks:
      - localai-hub

  redis:
    image: docker.io/valkey/valkey:8-alpine
    container_name: redis
    privileged: true
    command: sh -c "sysctl -w vm.overcommit_memory=1 && valkey-server --save 30 1 --loglevel warning"
    restart: unless-stopped
    networks:
      - localai-hub
    volumes:
      - redis-data:/data
    cap_drop:
      - ALL
    cap_add:
      - SETGID
      - SETUID
      - DAC_OVERRIDE
    depends_on:
      - sysctl-setter
    healthcheck:
      test: ["CMD-SHELL", "valkey-cli ping | grep -q PONG"]
      start_period: 5s
      interval: 1s
      timeout: 3s
      retries: 5
    logging: *loki-logging

  redis-exporter:
    image: oliver006/redis_exporter:latest
    container_name: redis-exporter
    command:
      - --redis.addr=redis://redis:6379 
      - --web.listen-address=:9121
      - --web.telemetry-path=/metrics
      - --namespace=redis
      - --export-client-list
      - --export-client-port
      - --include-system-metrics
    ports:
      - "9121:9121"
    restart: unless-stopped
    networks:
      - localai-hub
    depends_on:
      - redis
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9121/metrics"]
      interval: 30s
      timeout: 5s
      retries: 3
    logging: *loki-logging


  loki:
    image: grafana/loki:3.5.1
    container_name: loki
    ports:
      - "3100:3100"
    volumes:
      - ./loki-config:/etc/loki
      - loki-data:/loki
    command: -config.file=/etc/loki/local-config.yaml
    restart: unless-stopped
    networks:
      - localai-hub
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3100/ready"]
      interval: 30s
      timeout: 5s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "1m"
        max-file: "1"

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.52.1
    container_name: cadvisor
    ports:
      - "8081:8080"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    devices:
      - /dev/kmsg
    privileged: true
    restart: unless-stopped
    networks:
      - localai-hub
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/healthz"]
      interval: 30s
      timeout: 5s
      retries: 3
    logging: *loki-logging

  grafana:
    image: grafana/grafana:12.0.2
    container_name: grafana
    ports:
      - "3001:3000"
    env_file:
      - "./env/postgres.env"
      - "./env/grafana.env"
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana-provisioning:/etc/grafana/provisioning:ro
    restart: unless-stopped
    networks:
      - localai-hub
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 5s
      retries: 3
    logging: *loki-logging

  prometheus:
    image: prom/prometheus:v3.4.2
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - prometheus-data:/prometheus
      - ./prometheus:/etc/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--web.enable-otlp-receiver'
    restart: unless-stopped
    networks:
      - localai-hub
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 5s
      retries: 3
    logging: *loki-logging

  playwright:
    image: mcr.microsoft.com/playwright:v1.53.2-noble
    container_name: playwright
    command: npx playwright@1.49.1 run-server --port 3000 --host 0.0.0.0
    restart: unless-stopped
    networks:
      - localai-hub
    logging: *loki-logging

  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    ports:
      - "6333:6333"
      - "6334:6334"
    env_file:
      - "./env/qdrant.env"
    volumes:
      - qdrant-data:/qdrant/storage
    restart: unless-stopped
    networks:
      - localai-hub
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/healthz"]
      interval: 30s
      timeout: 5s
      retries: 3
    logging: *loki-logging

  postgres:
    image: postgres:16-alpine
    container_name: postgres
    env_file:
      - ./env/postgres.env
    networks:
      - localai-hub
    ports:
      - "5432:5432"
    restart: unless-stopped
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./postgres/init.sh:/docker-entrypoint-initdb.d/init.sh
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U $$POSTGRES_USER -d $$POSTGRES_DB" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    logging: *loki-logging

volumes:
  ollama:
    name: ollama
  open-webui:
    name: open-webui
  pipelines:
    name: pipelines
  redis-data:
    name: redis-data
  caddy-data:
    name: caddy-data
  searxng-cache:
    name: searxng-cache
  caddy-config:
    name: caddy-config
  grafana-data:
    name: grafana-data
  prometheus-data:
    name: prometheus-data
  qdrant-data:
    name: qdrant-data
  loki-data:
    name: loki-data
  postgres-data:
    name: postgres-data

networks:
  localai-hub:
    name: localai-hub
    driver: bridge